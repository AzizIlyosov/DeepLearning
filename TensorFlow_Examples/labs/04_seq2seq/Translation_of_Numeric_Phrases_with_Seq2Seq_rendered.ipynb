{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Translation of Numeric Phrases with Seq2Seq\n",
    "\n",
    "In the following we will try to build a **translation model from french phrases describing numbers** to the corresponding **numeric representation** (base 10).\n",
    "\n",
    "This is a toy machine translation task with a **restricted vocabulary** and a **single valid translation for each source phrase** which makes it more tractable to train on a laptop computer and easier to evaluate. Despite those limitations we expect that this task will highlight interesting properties of Seq2Seq models including:\n",
    "\n",
    "- the ability to **deal with different length** of the source and target sequences,\n",
    "- handling token with a **meaning that changes depending on the context** (e.g \"quatre\" vs \"quatre vingts\" in \"quatre cents\"),\n",
    "- basic counting and \"reasoning\" capabilities of LSTM and GRU models.\n",
    "\n",
    "The parallel text data is generated from a \"ground-truth\" Python function named `to_french_phrase` that captures common rules. Hyphenation was intentionally omitted to make the phrases more ambiguous and therefore make the translation problem slightly harder to solve (and also because Olivier had no particular interest hyphenation in properly implementing rules :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    21 vingt et un\n",
      "    80 quatre vingts\n",
      "    81 quatre vingt un\n",
      "   300 trois cents\n",
      "   213 deux cent treize\n",
      "  1100 mille cent\n",
      "  1201 mille deux cent un\n",
      "301000 trois cent un mille\n",
      " 80080 quatre vingt mille quatre vingts\n"
     ]
    }
   ],
   "source": [
    "from french_numbers import to_french_phrase\n",
    "\n",
    "for x in [21, 80, 81, 300, 213, 1100, 1201, 301000, 80080]:\n",
    "    print(str(x).rjust(6), to_french_phrase(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generating a Training Set\n",
    "\n",
    "The following will **generate phrases 20000 example phrases for numbers between 1 and 1,000,000** (excluded). We chose to over-represent small numbers by generating all the possible short sequences between 1 and `exhaustive`.\n",
    "\n",
    "We then split the generated set into non-overlapping train, validation and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from french_numbers import generate_translations\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "numbers, french_numbers = generate_translations(\n",
    "    low=1, high=int(1e6) - 1, exhaustive=5000, random_seed=0)\n",
    "num_train, num_dev, fr_train, fr_dev = train_test_split(\n",
    "    numbers, french_numbers, test_size=0.5, random_state=0)\n",
    "\n",
    "num_val, num_test, fr_val, fr_test = train_test_split(\n",
    "    num_dev, fr_dev, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5000, 5000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fr_train), len(fr_val), len(fr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2882 deux mille huit cent quatre vingt deux\n",
      "372200 trois cent soixante douze mille deux cents\n",
      "  2193 deux mille cent quatre vingt treize\n",
      "996418 neuf cent quatre vingt seize mille quatre cent dix huit\n",
      "  9172 neuf mille cent soixante douze\n"
     ]
    }
   ],
   "source": [
    "for i, fr_phrase, num_phrase in zip(range(5), fr_train, num_train):\n",
    "    print(num_phrase.rjust(6), fr_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2804 deux mille huit cent quatre\n",
      "  3898 trois mille huit cent quatre vingt dix huit\n",
      " 82996 quatre vingt deux mille neuf cent quatre vingt seize\n",
      "366346 trois cent soixante six mille trois cent quarante six\n",
      " 56006 cinquante six mille six\n"
     ]
    }
   ],
   "source": [
    "for i, fr_phrase, num_phrase in zip(range(5), fr_val, num_val):\n",
    "    print(num_phrase.rjust(6), fr_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Vocabularies\n",
    "\n",
    "Build the vocabularies from the training set only to get a chance to have some out-of-vocabulary words in the validation and test sets.\n",
    "\n",
    "First we need to introduce specific symbols that will be used to:\n",
    "- pad sequences\n",
    "- mark the beginning of translation\n",
    "- mark the end of translation\n",
    "- be used as a placehold for out-of-vocabulary symbols (not seen in the training set).\n",
    "\n",
    "Here we use the same convention as the [tensorflow seq2seq tutorial](https://www.tensorflow.org/tutorials/seq2seq):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "PAD, GO, EOS, UNK = START_VOCAB = ['_PAD', '_GO', '_EOS', '_UNK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To build the vocabulary we need to tokenize the sequences of symbols. For the digital number representation we use character level tokenization while whitespace-based word level tokenization will do for the French phrases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tokenize(sentence, word_level=True):\n",
    "    if word_level:\n",
    "        return sentence.split()\n",
    "    else:\n",
    "        return [sentence[i:i + 1] for i in range(len(sentence))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('1234', word_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mille', 'deux', 'cent', 'trente', 'quatre']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('mille deux cent trente quatre', word_level=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's now use this tokenization strategy to assign a unique integer token id to each possible token string found the traing set in each language ('French' and 'numeric'): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_vocabulary(tokenized_sequences):\n",
    "    rev_vocabulary = START_VOCAB[:]\n",
    "    unique_tokens = set()\n",
    "    for tokens in tokenized_sequences:\n",
    "        unique_tokens.update(tokens)\n",
    "    rev_vocabulary += sorted(unique_tokens)\n",
    "    vocabulary = {}\n",
    "    for i, token in enumerate(rev_vocabulary):\n",
    "        vocabulary[token] = i\n",
    "    return vocabulary, rev_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tokenized_fr_train = [tokenize(s, word_level=True) for s in fr_train]\n",
    "tokenized_num_train = [tokenize(s, word_level=False) for s in num_train]\n",
    "\n",
    "fr_vocab, rev_fr_vocab = build_vocabulary(tokenized_fr_train)\n",
    "num_vocab, rev_num_vocab = build_vocabulary(tokenized_num_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The two languages do not have the same vocabulary sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fr_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      _EOS 2\n",
      "       _GO 1\n",
      "      _PAD 0\n",
      "      _UNK 3\n",
      "      cent 4\n",
      "     cents 5\n",
      "      cinq 6\n",
      " cinquante 7\n",
      "      deux 8\n",
      "       dix 9\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "for k, v in sorted(fr_vocab.items())[:10]:\n",
    "    print(k.rjust(10), v)\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0 4\n",
      "         1 5\n",
      "         2 6\n",
      "         3 7\n",
      "         4 8\n",
      "         5 9\n",
      "         6 10\n",
      "         7 11\n",
      "         8 12\n",
      "         9 13\n",
      "      _EOS 2\n",
      "       _GO 1\n",
      "      _PAD 0\n",
      "      _UNK 3\n"
     ]
    }
   ],
   "source": [
    "for k, v in sorted(num_vocab.items()):\n",
    "    print(k.rjust(10), v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We also built the reverse mappings from token ids to token string representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_PAD', '_GO', '_EOS', '_UNK', 'cent', 'cents', 'cinq', 'cinquante', 'deux', 'dix', 'douze', 'et', 'huit', 'mille', 'neuf', 'onze', 'quarante', 'quatorze', 'quatre', 'quinze', 'seize', 'sept', 'six', 'soixante', 'treize', 'trente', 'trois', 'un', 'vingt', 'vingts']\n"
     ]
    }
   ],
   "source": [
    "print(rev_fr_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_PAD', '_GO', '_EOS', '_UNK', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "print(rev_num_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Seq2Seq with a single GRU architecture\n",
    "\n",
    "<img src=\"images/basic_seq2seq.png\" width=\"80%\" />\n",
    "\n",
    "From: [Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. \"Sequence to sequence learning with neural networks.\" NIPS 2014](https://arxiv.org/abs/1409.3215)\n",
    "\n",
    "\n",
    "\n",
    "For a given source sequence - target sequence pair, we will:\n",
    "- tokenize the source and target sequences;\n",
    "- reverse the order of the source sequence;\n",
    "- build the input sequence by concatenating the reversed source sequence and the target sequence in original order using the `_GO` token as a delimiter, \n",
    "- build the output sequence by appending the `_EOS` token to the source sequence.\n",
    "\n",
    "\n",
    "Let's do this as a function using the original string representations for the tokens so as to make it easier to debug:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Exercise**\n",
    "- Build a function which adapts a pair of tokenized sequences to the framework above.\n",
    "- The function should have a reverse_source as an option.\n",
    "\n",
    "*Note*: \n",
    "- The function should output two sequences of string tokens: one to be fed as the input and the other as expected output for the seq2seq network. We will handle the padding later;\n",
    "- Don't forget to insert the `_GO` and `_EOS` special symbols at the right locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/make_input_output.py\n",
    "def make_input_output(source_tokens, target_tokens, reverse_source=True):\n",
    "    if reverse_source:\n",
    "        source_tokens = source_tokens[::-1]\n",
    "    input_tokens = source_tokens + [GO] + target_tokens\n",
    "    output_tokens = target_tokens + [EOS]\n",
    "    return input_tokens, output_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_tokens, output_tokens = make_input_output(\n",
    "    ['cent', 'vingt', 'et', 'un'],\n",
    "    ['1', '2', '1'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['un', 'et', 'vingt', 'cent', '_GO', '1', '2', '1']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '1', '_EOS']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Vectorization of the parallel corpus\n",
    "\n",
    "Let's apply the previous transformation to each pair of (source, target) sequene and use a shared vocabulary to store the results in numpy arrays of integer token ids, with padding on the left so that all input / output sequences have the same length: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_tokenized_sequences = tokenized_fr_train + tokenized_num_train\n",
    "shared_vocab, rev_shared_vocab = build_vocabulary(all_tokenized_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max_length = 20  # found by introspection of our training set\n",
    "\n",
    "def vectorize_corpus(source_sequences, target_sequences, shared_vocab,\n",
    "                     word_level_source=True, word_level_target=True,\n",
    "                     max_length=max_length):\n",
    "    assert len(source_sequences) == len(target_sequences)\n",
    "    n_sequences = len(source_sequences)\n",
    "    source_ids = np.empty(shape=(n_sequences, max_length), dtype=np.int32)\n",
    "    source_ids.fill(shared_vocab[PAD])\n",
    "    target_ids = np.empty(shape=(n_sequences, max_length), dtype=np.int32)\n",
    "    target_ids.fill(shared_vocab[PAD])\n",
    "    numbered_pairs = zip(range(n_sequences), source_sequences, target_sequences)\n",
    "    for i, source_seq, target_seq in numbered_pairs:\n",
    "        source_tokens = tokenize(source_seq, word_level=word_level_source)\n",
    "        target_tokens = tokenize(target_seq, word_level=word_level_target)\n",
    "        \n",
    "        in_tokens, out_tokens = make_input_output(source_tokens, target_tokens)\n",
    "        \n",
    "        in_token_ids = [shared_vocab.get(t, UNK) for t in in_tokens]\n",
    "        source_ids[i, -len(in_token_ids):] = in_token_ids\n",
    "    \n",
    "        out_token_ids = [shared_vocab.get(t, UNK) for t in out_tokens]\n",
    "        target_ids[i, -len(out_token_ids):] = out_token_ids\n",
    "    return source_ids, target_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = vectorize_corpus(fr_train, num_train, shared_vocab,\n",
    "                                    word_level_target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 20)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deux mille huit cent quatre vingt deux'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2882'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0, 18, 38, 28, 14, 22, 23, 18,  1,  6,\n",
       "       12, 12,  6], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  6, 12,\n",
       "       12,  6,  2], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This looks good. In particular we can note:\n",
    "\n",
    "- the PAD=0 symbol at the beginning of the two sequences,\n",
    "- the input sequence has the GO=1 symbol to separate the source from the target,\n",
    "- the output sequence is a shifted version of the target and ends with EOS=2.\n",
    "\n",
    "Let's vectorize the validation and test set to be able to evaluate our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_val, Y_val = vectorize_corpus(fr_val, num_val, shared_vocab,\n",
    "                                word_level_target=False)\n",
    "X_test, Y_test = vectorize_corpus(fr_test, num_test, shared_vocab,\n",
    "                                  word_level_target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 20), (5000, 20))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 20), (5000, 20))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### A simple homogeneous Seq2Seq architecture\n",
    "\n",
    "To keep the architecture simple we will use the **same RNN model and weights for both the encoder part** (before the `_GO` token) **and the decoder part** (after the `_GO` token).\n",
    "\n",
    "We may GRU recurrent cell instead of LSTM because it is slightly faster to compute and should give comparable results.\n",
    "\n",
    "**Exercise:**\n",
    "- Build a Seq2Seq model:\n",
    "  - Start with an Embedding layer;\n",
    "  - Add a single GRU layer: the GRU layer should yield a sequence of output vectors, one at each timestep;\n",
    "  - Add a Dense layer to adapt the ouput dimension of the GRU layer to the dimension of the output vocabulary;\n",
    "  - Don't forget to insert some Dropout layer(s), especially after the Embedding layer.\n",
    "\n",
    "Note:\n",
    "- The output dimension of the Embedding layer should be smaller than usual be cause we have small vocabulary size;\n",
    "- The dimension of the GRU should be larger to give the Seq2Seq model enough \"working memory\" to memorize the full input sequence before decoding it;\n",
    "- Your model should output a shape `[batch, sequence_length, vocab_size]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/simple_seq2seq.py\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dropout, GRU, Dense\n",
    "\n",
    "vocab_size = len(shared_vocab)\n",
    "simple_seq2seq = Sequential()\n",
    "simple_seq2seq.add(Embedding(vocab_size, 32, input_length=max_length))\n",
    "simple_seq2seq.add(Dropout(0.2))\n",
    "simple_seq2seq.add(GRU(64, return_sequences=True))\n",
    "simple_seq2seq.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "# Here we use the sparse_categorical_crossentropy loss to be able to pass\n",
    "# integer-coded output for the token ids without having to convert to one-hot\n",
    "# codes\n",
    "simple_seq2seq.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's use a callback mechanism to automatically snapshot the best model found so far on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "best_model_fname = \"simple_seq2seq_checkpoint.h5\"\n",
    "best_model_cb = ModelCheckpoint(best_model_fname, monitor='val_loss',\n",
    "                                save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We need to use np.expand_dims trick on Y: this is required by Keras because of we use a sparse (integer-based) representation for the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruizhang/anaconda3/anaconda/lib/python3.6/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "Epoch 00000: val_loss improved from inf to 0.60855, saving model to simple_seq2seq_checkpoint.h5\n",
      "23s - loss: 1.0676 - val_loss: 0.6086\n",
      "Epoch 2/5\n",
      "Epoch 00001: val_loss improved from 0.60855 to 0.56051, saving model to simple_seq2seq_checkpoint.h5\n",
      "20s - loss: 0.5827 - val_loss: 0.5605\n",
      "Epoch 3/5\n",
      "Epoch 00002: val_loss improved from 0.56051 to 0.53664, saving model to simple_seq2seq_checkpoint.h5\n",
      "23s - loss: 0.5548 - val_loss: 0.5366\n",
      "Epoch 4/5\n",
      "Epoch 00003: val_loss improved from 0.53664 to 0.48266, saving model to simple_seq2seq_checkpoint.h5\n",
      "22s - loss: 0.5156 - val_loss: 0.4827\n",
      "Epoch 5/5\n",
      "Epoch 00004: val_loss improved from 0.48266 to 0.43141, saving model to simple_seq2seq_checkpoint.h5\n",
      "20s - loss: 0.4649 - val_loss: 0.4314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x12dcee518>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAGDCAYAAAALTociAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1266e98d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = simple_seq2seq.fit(X_train, np.expand_dims(Y_train, -1),\n",
    "                             validation_data=(X_val, np.expand_dims(Y_val, -1)),\n",
    "                             nb_epoch=5, verbose=2, batch_size=32,\n",
    "                             callbacks=[best_model_cb])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], '--', label='validation')\n",
    "plt.ylabel('negative log likelihood')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('Convergence plot for Simple Seq2Seq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's load the best model found on the validation set at the end of training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(40, 32), (32, 192), (64, 192), (192,), (64, 40), (40,)]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 20, 32)            1280      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 20, 64)            18624     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20, 40)            2600      \n",
      "=================================================================\n",
      "Total params: 22,504\n",
      "Trainable params: 22,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weights = simple_seq2seq.get_weights()\n",
    "print([w.shape for w in weights])\n",
    "# 18624 = 32*192 + 64*192 +192, where 192 = 64*3 \n",
    "simple_seq2seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "simple_seq2seq = load_model(best_model_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you don't have access to a GPU and cannot wait 10 minutes to for the model to converge to a reasonably good state, feel to use the pretrained model. This model has been obtained by training the above model for ~150 epochs. The validation loss is significantly lower than 1e-5. In practice it should hardly ever make any prediction error on this easy translation problem.\n",
    "\n",
    "Alternatively we will load this imperfect model (trained only to 50 epochs) with a validation loss of ~7e-4. This model makes funny translation errors so I would suggest to try it first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruizhang/anaconda3/anaconda/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  return cls(**config)\n",
      "/Users/ruizhang/anaconda3/anaconda/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(input_dim=40, activity_regularizer=None, output_dim=32, mask_zero=False, input_dtype=\"int32\", name=\"embedding_1\", input_length=20, trainable=True, batch_input_shape=[None, 20], embeddings_initializer=\"uniform\", embeddings_regularizer=None, embeddings_constraint=None)`\n",
      "  return cls(**config)\n",
      "/Users/ruizhang/anaconda3/anaconda/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(trainable=True, name=\"dropout_1\", rate=0.2)`\n",
      "  return cls(**config)\n",
      "/Users/ruizhang/anaconda3/anaconda/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  return cls(**config)\n",
      "/Users/ruizhang/anaconda3/anaconda/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(unroll=False, stateful=False, go_backwards=False, activation=\"tanh\", name=\"gru_1\", trainable=True, return_sequences=True, input_shape=(None, 32), units=256, kernel_initializer=\"glorot_uniform\", recurrent_initializer=\"orthogonal\", recurrent_activation=\"hard_sigmoid\", kernel_regularizer=None, bias_regularizer=None, recurrent_regularizer=None, dropout=0.0, recurrent_dropout=0.0, implementation=0)`\n",
      "  return cls(**config)\n",
      "/Users/ruizhang/anaconda3/anaconda/lib/python3.6/site-packages/keras/engine/topology.py:1242: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=256, activity_regularizer=None, activation=\"softmax\", name=\"dense_1\", trainable=True, units=40, kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Optimizer weight shape (40,) not compatible with provided weight shape (256, 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-18c70d94413b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#                                           '.keras/datasets/simple_seq2seq_pretrained.h5'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0msimple_seq2seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ruizhang/anaconda3/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    289\u001b[0m             optimizer_weight_values = [optimizer_weights_group[n] for n in\n\u001b[1;32m    290\u001b[0m                                        optimizer_weight_names]\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_weight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ruizhang/anaconda3/anaconda/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    101\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                                  \u001b[0;34m' not compatible with '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                                  'provided weight shape ' + str(w.shape))\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Optimizer weight shape (40,) not compatible with provided weight shape (256, 40)"
     ]
    }
   ],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "import os\n",
    "\n",
    "get_file(\"simple_seq2seq_partially_pretrained.h5\", \n",
    "         \"https://github.com/m2dsupsdlclass/lectures-labs/releases/\"\n",
    "         \"download/0.4/simple_seq2seq_partially_pretrained.h5\")\n",
    "\n",
    "filename = os.path.expanduser(os.path.join('~', \n",
    "                                           '.keras/datasets/simple_seq2seq_partially_pretrained.h5'))\n",
    "\n",
    "### Uncomment the following to replace for the fully trained network \n",
    "\n",
    "#get_file(\"simple_seq2seq_pretrained.h5\", \n",
    "#         \"https://github.com/m2dsupsdlclass/lectures-labs/releases/\"\n",
    "#         \"download/0.4/simple_seq2seq_pretrained.h5\")\n",
    "#filename = os.path.expanduser(os.path.join('~', \n",
    "#                                           '.keras/datasets/simple_seq2seq_pretrained.h5'))\n",
    "\n",
    "simple_seq2seq = load_model(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's have a look at a raw prediction on the first sample of the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fr_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In numeric array this is provided (along with the expected target sequence) as the following padded input sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "first_test_sequence = X_test[0:1]\n",
    "first_test_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Remember that the `_GO` (symbol indexed at `1`) separates the reversed source from the expected target sequence:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rev_shared_vocab[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Interpreting the model prediction\n",
    "\n",
    "**Exercise **:\n",
    "- Feed this test sequence into the model. What is the shape of the output?\n",
    "- Get the argmax of each output prediction to get the most likely symbols\n",
    "- Dismiss the padding / end of sentence\n",
    "- Convert to readable vocabulary using rev_shared_vocab\n",
    "\n",
    "*Interpretation*\n",
    "- Compare the output with the first example in numerical format `num_test[0]`\n",
    "- What do you think of this way of decoding? Is it correct to use it at inference time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/interpret_output.py\n",
    "prediction = simple_seq2seq.predict(first_test_sequence)\n",
    "print(\"prediction shape:\", prediction.shape)\n",
    "\n",
    "# Let's use `argmax` to extract the predicted token ids at each step:\n",
    "predicted_token_ids = prediction[0].argmax(-1)\n",
    "print(\"prediction token ids:\", predicted_token_ids)\n",
    "\n",
    "# We can use the shared reverse vocabulary to map \n",
    "# this back to the string representation of the tokens,\n",
    "# as well as removing Padding and EOS symbols\n",
    "predicted_numbers = [rev_shared_vocab[token_id] for token_id in predicted_token_ids\n",
    "                     if token_id not in (shared_vocab[PAD], shared_vocab[EOS])]\n",
    "print(\"predicted number:\", \"\".join(predicted_numbers))\n",
    "print(\"test number:\", num_test[0])\n",
    "\n",
    "# The model successfully predicted the test sequence.\n",
    "# However, we provided the full sequence as input, including all the solution\n",
    "# (except for the last number). In a real testing condition, one wouldn't\n",
    "# have the full input sequence, but only what is provided before the \"GO\"\n",
    "# symbol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the previous exercise we cheated a bit because we gave the complete sequence along with the solution in the input sequence. To correctly predict we need to predict one token at a time and reinject the predicted token in the input sequence to predict the next token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def greedy_translate(model, source_sequence, shared_vocab, rev_shared_vocab,\n",
    "                     word_level_source=True, word_level_target=True):\n",
    "    \"\"\"Greedy decoder recursively predicting one token at a time\"\"\"\n",
    "    # Initialize the list of input token ids with the source sequence\n",
    "    source_tokens = tokenize(source_sequence, word_level=word_level_source)\n",
    "    input_ids = [shared_vocab.get(t, UNK) for t in source_tokens[::-1]]\n",
    "    input_ids += [shared_vocab[GO]]\n",
    "\n",
    "    # Prepare a fixed size numpy array that matches the expected input\n",
    "    # shape for the model\n",
    "    input_array = np.empty(shape=(1, model.input_shape[1]),\n",
    "                           dtype=np.int32)\n",
    "    decoded_tokens = []\n",
    "    while len(input_ids) <= max_length:\n",
    "        # Vectorize a the list of input tokens as \n",
    "        # and use zeros padding.\n",
    "        input_array.fill(shared_vocab[PAD])\n",
    "        input_array[0, -len(input_ids):] = input_ids\n",
    "        \n",
    "        # Predict the next output: greedy decoding with argmax\n",
    "        next_token_id = model.predict(input_array)[0, -1].argmax()\n",
    "        \n",
    "        # Stop decoding if the network predicts end of sentence:\n",
    "        if next_token_id == shared_vocab[EOS]:\n",
    "            break\n",
    "            \n",
    "        # Otherwise use the reverse vocabulary to map the prediction\n",
    "        # back to the string space\n",
    "        decoded_tokens.append(rev_shared_vocab[next_token_id])\n",
    "        \n",
    "        # Append prediction to input sequence to predict the next\n",
    "        input_ids.append(next_token_id)\n",
    "\n",
    "    separator = \" \" if word_level_target else \"\"\n",
    "    return separator.join(decoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "phrases = [\n",
    "    \"un\",\n",
    "    \"deux\",\n",
    "    \"trois\",\n",
    "    \"onze\",\n",
    "    \"quinze\",\n",
    "    \"cent trente deux\",\n",
    "    \"cent mille douze\",\n",
    "    \"sept mille huit cent cinquante neuf\",\n",
    "    \"vingt et un\",\n",
    "    \"vingt quatre\",\n",
    "    \"quatre vingts\",\n",
    "    \"quatre vingt onze mille\",\n",
    "    \"quatre vingt onze mille deux cent deux\",\n",
    "]\n",
    "for phrase in phrases:\n",
    "    translation = greedy_translate(simple_seq2seq, phrase,\n",
    "                                   shared_vocab, rev_shared_vocab,\n",
    "                                   word_level_target=False)\n",
    "    print(phrase.ljust(40), translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Why does the partially trained network is able to correctly give the output for\n",
    "\n",
    "`\"sept mille huit cent cinquante neuf\"`\n",
    "\n",
    "but not for:\n",
    "\n",
    "`\"cent mille douze\"` ?\n",
    "\n",
    "The answer is as following:\n",
    "- it is rather easy for the network to learn a correspondance between symbols (first case), by dismissing `\"cent\"` and `\"mille\"`\n",
    "- outputing the right amount of symbols, especially `0s` for `\"cent mille douze\"` requires more reasoning and ability to count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "phrases = [\n",
    "    \"quatre vingt et un\",\n",
    "    \"quarante douze\",\n",
    "    \"onze cent soixante vingt quatorze\",\n",
    "]\n",
    "for phrase in phrases:\n",
    "    translation = greedy_translate(simple_seq2seq, phrase,\n",
    "                                   shared_vocab, rev_shared_vocab,\n",
    "                                   word_level_target=False)\n",
    "    print(phrase.ljust(40), translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model evaluation\n",
    "\n",
    "Because **we expect only one correct translation** for a given source sequence, we can use **phrase-level accuracy** as a metric to quantify our model quality.\n",
    "\n",
    "Note that **this is not the case for real translation models** (e.g. from French to English on arbitrary sentences). Evaluation of a machine translation model is tricky in general. Automated evaluation can somehow be done at the corpus level with the [BLEU score](https://en.wikipedia.org/wiki/BLEU) (bilingual evaluation understudy) given a large enough sample of correct translations provided by certified translators but its only a noisy proxy.\n",
    "\n",
    "The only good evaluation is to give a large enough sample of the model predictions on some test sentences to certified translators and ask them to give an evaluation (e.g. a score between 0 and 6, 0 for non-sensical and 6 for the hypothetical perfect translation). However in practice this is very costly to do.\n",
    "\n",
    "Fortunately we can just use phrase-level accuracy on a our very domain specific toy problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def phrase_accuracy(model, num_sequences, fr_sequences, n_samples=300,\n",
    "                    decoder_func=greedy_translate):\n",
    "    correct = []\n",
    "    n_samples = len(num_sequences) if n_samples is None else n_samples\n",
    "    for i, num_seq, fr_seq in zip(range(n_samples), num_sequences, fr_sequences):\n",
    "        if i % 100 == 0:\n",
    "            print(\"Decoding %d/%d\" % (i, n_samples))\n",
    "\n",
    "        predicted_seq = decoder_func(simple_seq2seq, fr_seq,\n",
    "                                     shared_vocab, rev_shared_vocab,\n",
    "                                     word_level_target=False)\n",
    "        correct.append(num_seq == predicted_seq)\n",
    "    return np.mean(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Phrase-level test accuracy: %0.3f\"\n",
    "      % phrase_accuracy(simple_seq2seq, num_test, fr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Phrase-level train accuracy: %0.3f\"\n",
    "      % phrase_accuracy(simple_seq2seq, num_train, fr_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Bonus: Decoding with a Beam Search\n",
    "\n",
    "Instead of decoding with greedy strategy that only considers the most-likely next token at each prediction, we can hold a priority queue of the most promising top-n sequences ordered by loglikelihoods.\n",
    "\n",
    "This could potentially improve the final accuracy of an imperfect model: indeed it can be the case that the most likely sequence (based on the conditional proability estimated by the model) starts with a character that is not the most likely alone.\n",
    "\n",
    "**Bonus Exercise:**\n",
    "- build a beam_translate function which decodes candidate translations with a beam search strategy\n",
    "- use a list of candidates, tracking `beam_size` candidates and their corresponding likelihood\n",
    "- compute predictions for the next outputs by using predict with a batch of the size of the beam\n",
    "- be careful to stop appending results if EOS symbols have been found for each candidate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def beam_translate(model, source_sequence, shared_vocab, rev_shared_vocab,\n",
    "                   word_level_source=True, word_level_target=True,\n",
    "                   beam_size=10, return_ll=False):\n",
    "    \"\"\"Decode candidate translations with a beam search strategy\n",
    "    \n",
    "    If return_ll is False, only the best candidate string is returned.\n",
    "    If return_ll is True, all the candidate strings and their loglikelihoods\n",
    "    are returned.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/beam_search.py\n",
    "def beam_translate(model, source_sequence, shared_vocab, rev_shared_vocab,\n",
    "                   word_level_source=True, word_level_target=True,\n",
    "                   beam_size=10, return_ll=False):\n",
    "    \"\"\"Decode candidate translations with a beam search strategy\n",
    "    \n",
    "    If return_ll is False, only the best candidate string is returned.\n",
    "    If return_ll is True, all the candidate strings and their loglikelihoods\n",
    "    are returned.\n",
    "    \"\"\"\n",
    "    # Initialize the list of input token ids with the source sequence\n",
    "    source_tokens = tokenize(source_sequence, word_level=word_level_source)\n",
    "    input_ids = [shared_vocab.get(t, UNK) for t in source_tokens[::-1]]\n",
    "    input_ids += [shared_vocab[GO]]\n",
    "    \n",
    "    # initialize loglikelihood, input token ids, decoded tokens for\n",
    "    # each candidate in the beam\n",
    "    candidates = [(0, input_ids[:], [], False)]\n",
    "\n",
    "    # Prepare a fixed size numpy array that matches the expected input\n",
    "    # shape for the model\n",
    "    input_array = np.empty(shape=(beam_size, model.input_shape[1]),\n",
    "                           dtype=np.int32)\n",
    "    while any([not done and (len(input_ids) < max_length)\n",
    "               for _, input_ids, _, done in candidates]):\n",
    "        # Vectorize a the list of input tokens and use zeros padding.\n",
    "        input_array.fill(shared_vocab[PAD])\n",
    "        for i, (_, input_ids, _, done) in enumerate(candidates):\n",
    "            if not done:\n",
    "                input_array[i, -len(input_ids):] = input_ids\n",
    "        \n",
    "        # Predict the next output in a single call to the model to amortize\n",
    "        # the overhead and benefit from vector data parallelism on GPU.\n",
    "        next_likelihood_batch = model.predict(input_array)\n",
    "        \n",
    "        # Build the new candidates list by summing the loglikelood of the\n",
    "        # next token with their parents for each new possible expansion.\n",
    "        new_candidates = []\n",
    "        for i, (ll, input_ids, decoded, done) in enumerate(candidates):\n",
    "            if done:\n",
    "                new_candidates.append((ll, input_ids, decoded, done))\n",
    "            else:\n",
    "                next_loglikelihoods = np.log(next_likelihood_batch[i, -1])\n",
    "                for next_token_id, next_ll in enumerate(next_loglikelihoods):\n",
    "                    new_ll = ll + next_ll\n",
    "                    new_input_ids = input_ids[:]\n",
    "                    new_input_ids.append(next_token_id)\n",
    "                    new_decoded = decoded[:]\n",
    "                    new_done = done\n",
    "                    if next_token_id == shared_vocab[EOS]:\n",
    "                        new_done = True\n",
    "                    if not new_done:\n",
    "                        new_decoded.append(rev_shared_vocab[next_token_id])\n",
    "                    new_candidates.append(\n",
    "                        (new_ll, new_input_ids, new_decoded, new_done))\n",
    "        \n",
    "        # Only keep a beam of the most promising candidates\n",
    "        new_candidates.sort(reverse=True)\n",
    "        candidates = new_candidates[:beam_size]\n",
    "\n",
    "    separator = \" \" if word_level_target else \"\"\n",
    "    if return_ll:\n",
    "        return [(separator.join(decoded), ll) for ll, _, decoded, _ in candidates]\n",
    "    else:\n",
    "        _, _, decoded, done = candidates[0]\n",
    "        return separator.join(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "candidates = beam_translate(simple_seq2seq, \"cent mille un\",\n",
    "                            shared_vocab, rev_shared_vocab,\n",
    "                            word_level_target=False,\n",
    "                            return_ll=True, beam_size=10)\n",
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "candidates = beam_translate(simple_seq2seq, \"quatre vingts\",\n",
    "                            shared_vocab, rev_shared_vocab,\n",
    "                            word_level_target=False,\n",
    "                            return_ll=True, beam_size=10)\n",
    "candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Accuracy with Beam Search Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Phrase-level test accuracy: %0.3f\"\n",
    "      % phrase_accuracy(simple_seq2seq, num_test, fr_test,\n",
    "                        decoder_func=beam_translate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Phrase-level train accuracy: %0.3f\"\n",
    "      % phrase_accuracy(simple_seq2seq, num_train, fr_train,\n",
    "                        decoder_func=beam_translate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "When using the partially trained model the test phrase-level is slightly better (0.38 vs 0.37) with the beam decoder than with the greedy decoder. However the improvement is not that important on our toy task. Training the model to convergence would yield a perfect score on the test set anyway.\n",
    "\n",
    "Properly tuned beam search decoding can be critical to improve the quality of Machine Translation systems trained on natural language pairs though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Going Further\n",
    "\n",
    "We only scratched the surface of sequence-to-sequence systems. To go further, we recommend reading the initial [Sequence to Sequence paper](https://arxiv.org/abs/1409.3215) as well as the following developments, citing this work. Furthermore, here are a few pointers on how to go further if you're interested.\n",
    "\n",
    "### Improved model\n",
    "\n",
    "- Add multiple, larger GRU layers and more dropout regularization.\n",
    "- This should make it possible train a perfect translation model with a smaller amount of labeled samples. Try to train a seq2seq model with only 4000 training sequences or even fewer without overfitting.\n",
    "- You will need a GPU and more training time for that.\n",
    "\n",
    "### Reverse translation: Numeric to French\n",
    "\n",
    "- Build a model, with the same data from Numeric to French\n",
    "- The model should fine work with the same kind of architecture\n",
    "\n",
    "\n",
    "### Separated Encoder-Decoder\n",
    "\n",
    "We may want to build a model with a separated encoder and decoder, to improve performance and be more flexible with the architecture.\n",
    "\n",
    "- The Keras Framework isn't well suited for building an encoder-decoder model up to now;\n",
    "- This repo is an attempt at doing so https://github.com/farizrahman4u/seq2seq - untested;\n",
    "- You might rather want to use TensorFlow directly or PyTorch. \n",
    "\n",
    "### Attention models\n",
    "\n",
    "Having a separated encoder-decoder framework also enables us to build an attention-model:\n",
    "- A good implementation is available for translation here: http://opennmt.net/PythonGuide/\n",
    "- TensorFlow also has working examples: https://www.tensorflow.org/tutorials/seq2seq\n",
    "\n",
    "Attention models are efficient to model longer sequences, to find alignment between input and output sequences, and to model different parts of sequences with seperated meanings\n",
    "\n",
    "\n",
    "### Mastering Neural Machine Translation\n",
    "\n",
    "In complement to studying the TensorFlow seq2seq and OpenNMT code base, you might also want to read the following 55 pages tutorial:\n",
    "\n",
    "[Neural Machine Translation and Sequence-to-sequence Models: A Tutorial](https://arxiv.org/abs/1703.01619) by Graham Neubig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
